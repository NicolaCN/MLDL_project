{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKDlAuZvxB1D1VPGLs7dp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeTornio/MLDL_project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaGch_uGq0yR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "import datasets.ss_transforms as sstr\n",
        "import datasets.np_transforms as nptr\n",
        "\n",
        "from torch import nn\n",
        "from client import Client\n",
        "from datasets.femnist import Femnist\n",
        "from server import Server\n",
        "from utils.args import get_parser\n",
        "from datasets.idda import IDDADataset\n",
        "from models.deeplabv3 import deeplabv3_mobilenetv2\n",
        "from utils.stream_metrics import StreamSegMetrics, StreamClsMetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "1dnW_t3qriTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_num_classes(dataset):\n",
        "    if dataset == 'idda':\n",
        "        return 16\n",
        "    if dataset == 'femnist':\n",
        "        return 62\n",
        "    raise NotImplementedError"
      ],
      "metadata": {
        "id": "ug8hb3IYrkhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init(args):\n",
        "    if args.model == 'deeplabv3_mobilenetv2':\n",
        "        return deeplabv3_mobilenetv2(num_classes=get_dataset_num_classes(args.dataset))\n",
        "    if args.model == 'resnet18':\n",
        "        model = resnet18()\n",
        "        model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        model.fc = nn.Linear(in_features=512, out_features=get_dataset_num_classes(args.dataset))\n",
        "        return model\n",
        "    if args.model == 'cnn':\n",
        "        # TODO: missing code here!\n",
        "        raise NotImplementedError\n",
        "    raise NotImplementedError"
      ],
      "metadata": {
        "id": "6LZhhacYrmWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(args):\n",
        "    # TODO: test your data augmentation by changing the transforms here!\n",
        "    if args.model == 'deeplabv3_mobilenetv2':\n",
        "        train_transforms = sstr.Compose([\n",
        "            sstr.RandomResizedCrop((512, 928), scale=(0.5, 2.0)),\n",
        "            sstr.ToTensor(),\n",
        "            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        test_transforms = sstr.Compose([\n",
        "            sstr.ToTensor(),\n",
        "            sstr.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    elif args.model == 'cnn' or args.model == 'resnet18':\n",
        "        train_transforms = nptr.Compose([\n",
        "            nptr.ToTensor(),\n",
        "            nptr.Normalize((0.5,), (0.5,)),\n",
        "        ])\n",
        "        test_transforms = nptr.Compose([\n",
        "            nptr.ToTensor(),\n",
        "            nptr.Normalize((0.5,), (0.5,)),\n",
        "        ])\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return train_transforms, test_transforms"
      ],
      "metadata": {
        "id": "0th0_EevroPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_femnist_dir(data_dir):\n",
        "    data = defaultdict(lambda: {})\n",
        "    files = os.listdir(data_dir)\n",
        "    files = [f for f in files if f.endswith('.json')]\n",
        "    for f in files:\n",
        "        file_path = os.path.join(data_dir, f)\n",
        "        with open(file_path, 'r') as inf:\n",
        "            cdata = json.load(inf)\n",
        "        data.update(cdata['user_data'])\n",
        "    return data"
      ],
      "metadata": {
        "id": "mxKNteNrrqTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_femnist_data(train_data_dir, test_data_dir):\n",
        "    return read_femnist_dir(train_data_dir), read_femnist_dir(test_data_dir)"
      ],
      "metadata": {
        "id": "bMGxWPhLrskH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets(args):\n",
        "\n",
        "    train_datasets = []\n",
        "    train_transforms, test_transforms = get_transforms(args)\n",
        "\n",
        "    if args.dataset == 'idda':\n",
        "        root = 'data/idda'\n",
        "        with open(os.path.join(root, 'train.json'), 'r') as f:\n",
        "            all_data = json.load(f)\n",
        "        for client_id in all_data.keys():\n",
        "            train_datasets.append(IDDADataset(root=root, list_samples=all_data[client_id], transform=train_transforms,\n",
        "                                              client_name=client_id))\n",
        "        with open(os.path.join(root, 'test_same_dom.txt'), 'r') as f:\n",
        "            test_same_dom_data = f.read().splitlines()\n",
        "            test_same_dom_dataset = IDDADataset(root=root, list_samples=test_same_dom_data, transform=test_transforms,\n",
        "                                                client_name='test_same_dom')\n",
        "        with open(os.path.join(root, 'test_diff_dom.txt'), 'r') as f:\n",
        "            test_diff_dom_data = f.read().splitlines()\n",
        "            test_diff_dom_dataset = IDDADataset(root=root, list_samples=test_diff_dom_data, transform=test_transforms,\n",
        "                                                client_name='test_diff_dom')\n",
        "        test_datasets = [test_same_dom_dataset, test_diff_dom_dataset]\n",
        "\n",
        "    elif args.dataset == 'femnist':\n",
        "        niid = args.niid\n",
        "        train_data_dir = os.path.join('data', 'femnist', 'data', 'niid' if niid else 'iid', 'train')\n",
        "        test_data_dir = os.path.join('data', 'femnist', 'data', 'niid' if niid else 'iid', 'test')\n",
        "        train_data, test_data = read_femnist_data(train_data_dir, test_data_dir)\n",
        "\n",
        "        train_transforms, test_transforms = get_transforms(args)\n",
        "\n",
        "        train_datasets, test_datasets = [], []\n",
        "\n",
        "        for user, data in train_data.items():\n",
        "            train_datasets.append(Femnist(data, train_transforms, user))\n",
        "        for user, data in test_data.items():\n",
        "            test_datasets.append(Femnist(data, test_transforms, user))\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return train_datasets, test_datasets\n"
      ],
      "metadata": {
        "id": "PaJuFYB9ruLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_metrics(args):\n",
        "    num_classes = get_dataset_num_classes(args.dataset)\n",
        "    if args.model == 'deeplabv3_mobilenetv2':\n",
        "        metrics = {\n",
        "            'eval_train': StreamSegMetrics(num_classes, 'eval_train'),\n",
        "            'test_same_dom': StreamSegMetrics(num_classes, 'test_same_dom'),\n",
        "            'test_diff_dom': StreamSegMetrics(num_classes, 'test_diff_dom')\n",
        "        }\n",
        "    elif args.model == 'resnet18' or args.model == 'cnn':\n",
        "        metrics = {\n",
        "            'eval_train': StreamClsMetrics(num_classes, 'eval_train'),\n",
        "            'test': StreamClsMetrics(num_classes, 'test')\n",
        "        }\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "0H9f_x-Xrwvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_clients(args, train_datasets, test_datasets, model):\n",
        "    clients = [[], []]\n",
        "    for i, datasets in enumerate([train_datasets, test_datasets]):\n",
        "        for ds in datasets:\n",
        "            clients[i].append(Client(args, ds, model, test_client=i == 1))\n",
        "    return clients[0], clients[1]"
      ],
      "metadata": {
        "id": "CbaAjj3lrz1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    parser = get_parser()\n",
        "    args = parser.parse_args()\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    print(f'Initializing model...')\n",
        "    model = model_init(args)\n",
        "    model.cuda()\n",
        "    print('Done.')\n",
        "\n",
        "    print('Generate datasets...')\n",
        "    train_datasets, test_datasets = get_datasets(args)\n",
        "    print('Done.')\n",
        "\n",
        "    metrics = set_metrics(args)\n",
        "    train_clients, test_clients = gen_clients(args, train_datasets, test_datasets, model)\n",
        "    server = Server(args, train_clients, test_clients, model, metrics)\n",
        "    server.train()"
      ],
      "metadata": {
        "id": "8g2ehx2pr1vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "Z2qwmXunr3X4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}